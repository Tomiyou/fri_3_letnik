\chapter[Benchmark orodja]{Benchmark orodja}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\thepage}
\fancyhead[RE,LO]{\leftmark}

\huge Žiga Šebenik, Tomaž Mrežar
\normalsize
\bigskip

\section{Opis problema}
Na voljo je več brezplačnih benchmark orodij za določanje zmogljivosti računalniških sistemov. V tem poglavju bomo našteli najbolj uporabljena brezplačna orodja v praksi.
Vsako orodje bova opisala in naštela njihove prepoznavne značilnosti in prednosti pred drugimi.
  


\section{Benchmark orodja}
Obstaja več vrst benchmark orodij. Testi, ki jih benchmark orodja izvajajo se lahko razlikujejo med seboj vendar so osnovne funkcionalnosti testov skoraj povsod enake. Skorajda vsako orodje testira dosegljivost sistemov, upočasnitve delovanja, latenco sistema in prepustnost sistema. Orodja bova delila na dve skupini, prva skupina bodo orodja, ki so brezplačna, medtem ko bodo v drugo skupino spadala orodja, ki so plačljiva, brezplačna za določen čas ali pa imajo v brezplačni verziji omejene funkcionalnosti.

\section{Brezplačna orodja}
Brezplačni orodji sta sledeči:
\begin{itemize}
\item ročno benchmark testiranje;
\item PerfKit Benchmarker;
\end{itemize}

\subsection{Ročno benchmark testiranje}
Zelo preprosta izbira, ki nam je na voljo, je da preprosto sami testiramo zmogljivost oblačnih storitev s pomočjo več različnih orodij,pri čemer je vsako namenjeno specifičnemu delu sistema. Na voljo nam je veliko zastonjskih orodij, precej jih je tudi odprtokodnih, znani med njimi pa so ping, Geekbench, fio, iPerf... Testiramo lahko zmogljivost posameznega strežnika, gruče ali pa celotnega oblaka. Njihova prednost je, da so preprosta in fleksibilna, vendar pa moramo več dela opraviti sami.

\subsection{PerfKit Benchmarker}
PerfKit Benchmarker je odprtokodno orodje uporabljamo za meritve in primerjave oblačnih performans.
Podpira več večjih oblačnih ponudnikov, kot sta Google Cloud Platform in Amazon Web Services, pa tudi mnoge druge.
PerfKit Benchmarker meri končni čas za zagotavljanje virov v oblaku in tudi vse osnovne oblačne meritve naštete v predhodnem razdelku. PerfKit Benchmarker zmanjšuje kompleksnost v zaganjanju testov na oblačnih ponudnikih z enotnimi in preprostimi ukazi.
Vsebuje tudi množice javnih testov za uporabo. Vsi testi se zaženejo z privzeto konfiguracijo, ki ni nastavljena v prid nobenemu ponudniku oblačnih storitev. To ponuja možnost testiranja na več različnih oblačnih platformah.
V bistvu je Perfkit Benchmarker le orodje, ki avtomatizira zagon ostalih, ozko nameskih orodij za test posameznih metrik platforme. Vsa orodja, ki jih uporablja so odprtokodna in bi jih lahko pognali sami, vendar nam Perfkit Benchmarker, zmanjša količino dela, saj ima prilagojene skripte za vse večje ponudnike.

\section{Plačljiva orodja}
Plačljiva orodja so sledeča:
\begin{itemize}
\item SPEC Cloud® IaaS 2018;
\item Cloud Spectator;
\item Cloud Performance Benchmark;
\item Technology Business Research, Inc.;
\end{itemize}

\subsection{SPEC Cloud® IaaS 2018}

SPEC Cloud® IaaS 2018 testira delovanje infrastrukture kot storitev oblačnih implementacij. Podpira testiranje javnih in zasebnih oblakov. Orodje deluje nad strežbo storitve, kot tudi nad izvajanjem storitve oblaka z uporabo vhodno izhodnih in CPE intenzivnih del. Vsako delo se zažene kot distribuirana aplikacija narejena iz 6 ali 7 instanc, ki obremenijo oblakove resource (CPE, diski in omrežje). Delo bo teklo dokler testi ne naredijo več kakovosti storitve. Administrator lahko tudi omeji število aplikacij kreiranih med izvedbo.
Orodje nam omogoča obremeniti računsko zmogljivost, shrambo in omrežje oblaka. Pri tem pa ne potrebuje hypervizorja ali virtualizacijske plasti in uporablja delovne obremenitve, ki spominjajo na tiste, ki običajno delujejo v oblaku, kot so aplikacije za socialne medije in velika analiza podatkov.
SPEC Cloud izdaja poročila, ki ne grejo tako v detajle posameznega dela platforme ter izdajajo ločene metrike za vsak del platforme, ampak testirajo zmogljivost ponudikove platforme kot celote. Merijo čas stvaritve, konfiguracije in zagona instanc oz. virtualnih strojev, latenco vstavitve oz. branja iz baze na postavljeni virtualki, prepustnost, skalabilnost. Vse metrike so merjene v sekundah oz. operacijah na sekundo.

\subsection{Cloud Spectator}

Cloud Spectator sicer ni orodje, ampak podjetje, ki ponuja benchmarking in konzultacijo glede oblačnih storitev. Podjetjem pomaga z analizo različnih ponudnikov oblačnih storitev in testira zmogljivost njihove infrastrukture ter svetuje pri ekonomskih odločitvah. Namenjen je tako primerjavi ponudnikov oblačnih storitev, kot tudi ponudnikom samim, da lahko analizirajo zmogljivost svoje infrastrukture. Nudili naj bi sposobnost izbire pravega ponudnika, kjer stranka postavi zahteve svoje aplikacije, Cloud spectator pa s kombinacijo zahtevosti strankine aplikacije, zmogljivosti infrastrukture različnih ponudnikov in njihovih cenikov, izbere pravega ponudnika.
Poročilo vrača rezultate v obliki VM Performance Sore in CloudSpecs Score. Nobeden od njiju nima posebne merske enote, saj je VM Performance Score le povprečje točk, ki jih vrneta Geekbench 4 in fio, tako da imata oba enak prispevek k točkam. CloudSpecs Score se izračuna kot VM Performance Score, ki je utežen s ceno, tako da dobimo zmogljivost na ceno, ki naj bi strankam omogočala lažjo izbiro pravega ponudnika platforme.

\subsection{Cloud Performance Benchmark}

Cloud Performance Benchmark je poročilo o največjih petih ponudnikih Amazon Web Services, Google Cloud Platform, Microsoft Azure, IBM Cloud in Alibaba Cloud. Zagotavljalo naj bi nepristransko strokovno poročilo, ki je podprto z raznimi metrikami. Poročilo primerja infrastrukturo posameznega ponudnika in pokaže kako ta infrastruktura njihovega vpliva na zmogljivost ter jih seveda primerja med seboj. Prav tako se dotakne geografskih razlik in njihov vpliv na zmogljivost.
Poročilo ne vsebuje le kvantitativnih podatkov o posameznih platformah, temveč tudi veliko več kvantitativnih in statističnih podatkov o predvidljivosti posameznih metrik poleg razlag arhitektur vsake platforme. Poročilo je zelo poglobljeno, kvantitativne metrike pa se tičejo predvsem omrežja, saj je velik poudarek na latenci, tako izven kot znotraj platforme, ter izgubi paketov. Veliko podatkov najdemo tudi o vplivu geografskih pozicij na kakovost omrežja vsake platforme, vse podprto z statistično analizo obeh metrik.

\subsection{Technology Business Research, Inc.}

Technology Business Research, Inc. je podjetje, ki prav tako nudi storitve tako ponudnikom oblačnih storitev, kot tudi njihovim strankam. Ponudnikom nudijo podatke o trgu, finančne podatke o ponudnikih programske opreme, napovedi, strategije prodaje, itd. Ponudnikom oblačnih storitev pa nudijo podatke o ponudnikih le teh storitev, zmogljivosti ponudnikove infrastrukture za strankin primer uporabe ter tudi prihajajoče trende, ki se bodo posluževali in vplivali na zmogljivost oblačnih sistemov.
TBR Inc. je bolj usmerjeno v svetovanje situaciji na trgu, kot pa poglobljeni analizi metrik in zmogljivosti. Sledijo trendom in priložnostim na trgu, napovedujejo nove trende in sledijo finančnim podatkov ponudnikov platform. Njihov glavni cilj je direktni stik in osebno svetovanje strankam, zato nisem uspel najti nobenih uporabnih podatkov o njihovi metodologiji oz. metrikah.


\section{Implementacija merilnega okolja}
Na oblaku Microsoft Azure sva ustvarila račun in na njem postavila virtualni stroj, ki poganja Ubuntu 18.04. Na tej virtualki sva ročno pognala več benchmark testov, saj googlov odprtokodni Perfkit Benchmarker ni deloval. Le ta se namreč zanaša na avtomatsko ustvarjanje virtualnih strojev, zastonjski račun na Azure pa to omejuje. Pognala sva odprtokodna orodja:
\begin{itemize}
\item Geekbench 3 = uporabljen predvsem za test CPE zmogljivosti;
\item  test pasovne širine omrežja in dostop do interneta;
\item  latenca diskovja;
\item  zmogljivost diskovja;
\end{itemize}

\subsection{Tehnične specifikacije računalnika}
Specifikacije računalnika na katerem teče virtualni stroj so sledeče:

\begin{itemize}
\item OS: Ubuntu 18.04.4 LTS 5.0.0-1032-azure x86\_64
\item CPE: Intel Xeon Platinum 8168 @ 2.69 GHz 1 processor, 2 threads
\item RAM: 4 GB
\item Disk: 32 GB SSD
\end{itemize}
Ker se računalnik nahaja nekje v Microsoftovem strežniškem centru in ker uporabljava zastonjski račun na Azure, nimava na razpolago celotnega računalnika, saj na njem verjetno teče tudi kakšna druga virtualka, kar zna vplivati na rezultate meritev. Omenjene specifikacije računalnika so le te, ki jih imava na voljo na virtualki.


\section{Rezultati meritev}

V naslednjih razdelkih bova predstavila testna orodja uporabljena na virtualnem računalniku in dobljene rezultate.

\subsection{Geekbench 3}
Najprej sva pognala Geekbench 3, benchmark, ki se uporablja za testiranje CPE zmogljivosti. Imel naj bi to prednost pred klasičnimi testi CPE, da simulira tako breme na procesorju, ki dobro ponazarja produkcijsko okolje med izvajanjem realnih programov, in ne samo sintetični breme. Prav tako Geekbench dodobra obremeni računalnik, da lahko vidimo zmogljivost ob velikem stresu. Še ena dobra stvar kar se tiče Geekbench-a je, da je zelo razširjen, kar pomeni da lahko najdemo veliko različnih rezultatov testov za različne konfiguracije računalnikov, vendar pa to ne pomeni da je zanesljiv. Obstajajo namreč primeri, kjer ima strežniški CPE slabšo oceno kot nek mobilni CPE, saj Geekbench ne testira termalnih zmogljivosti, prav tako pa so razlike med rezultati na različnih operacijskih sistemih. Čeprav Geekbench uporabi več različnih testov, iz povzetka vseh teh testov vrne dve glavni številki: Single-core točke in Multi-core točke, ki sami po sebi nič ne pomenita in nimata merskih enot, velja pa višje je, bolje je. Šele ko ju primerjamo z ostalimi sistemi, dobimo neko sliko zmogljivosti. 

Na sliki \ref{fig:1_geekbench1} so predstavljeni rezultati večih algoritmov za performanse celih števil. Algoritmi se izvajajo na enem jedru procesorja in na večih.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{Img/geekbench1.png}
    \caption{Cela števila.}
    \label{fig:1_geekbench1}
\end{figure} Na sliki \ref{fig:2_geekbench2} so predstavljeni rezultati večih algoritmov za performanse števil v plavajoči vejici. Algoritmi se izvajajo na enem jedru procesorja in na večih.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{Img/geekbench2.png}
    \caption{Plavajoča vejica.}
    \label{fig:2_geekbench2}
\end{figure} Na sliki \ref{fig:3_geekbench3} so predstavljeni rezultati za testiranje spomina. Testira se z kopiranjem na večih jedrih in na enem jedru procesorja.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{Img/geekbench3.png}
    \caption{Performanse spomina.}
    \label{fig:3_geekbench3}
\end{figure}

\subsection{iPerf}
Naslednji benchmark, ki sva ga pognala je iperf, ki meri podatke o omrežju kot sta upload in download pasovno širino. Meri jih v bajt/sekunda, kjer prilagodi prefix od bajta glede na hitrost omrežja. Test sva pognala nad omrežjem med nama in virtualnim strojem. Čeprav bi lahko v najinem primeru podatke popačila hitrost ponudnika interneta na najini strani, pa temu verjetno ni tako, saj sva testirala na omrežju z 12 MB/s prenosa. Nisva prepričana, ali isto velja tudi za upload hitrost, latence pa nisva testirala, saj se strežnik nahaja na nizozemskem in latenca zaradi geografske lokacije pač je kakršna je. Iperf nama vrne povprečno hitrost prenosa podatkov 2,71 MB/s in 2,53 hitrost uploada podatkov, kjer velja, da večje številke pomenijo boljše performanse. Na sliki \ref{fig:4_iperf1} so predstavljeni rezultati testa iPerf, kjer lahko vidimo hitrosti prenosa na intervalih.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{Img/iperf1.png}
    \caption{test iPerf.}
    \label{fig:4_iperf1}
\end{figure}


\subsection{ioPing}
Tretji benchmark, ki sva ga izbrala je ioPing. Prednost ioPing-a naj bi bila njegova preprost, saj je zelo podoben znanemu ukazu ping, le da je namenjen testu diskovja v računalniku. Ni namenjen testiranju diskovja pod naporom, zanima ga le latenca zahtev za pisanje/branje. Le ta je izredno pomembna za podatkovne baze, ki niso pod velikim stresom zaradi števila zahtev, vendar bi njihov opazen zamik pri odzivu negativno vplival na uporabniško izkušnjo. Latenca nima velikega pomena pri večih asinhronih operacijah pisanja, saj je to veliko bolj odvisno od prepustnosti diska. Zato sva pognala testa latence pri sinhronih oz. zaporednih operacijah pisanja in latenci pri asinhronih operacijah branja. ioPing poda rezultate latence v obliki sekund, seveda pa prilagodi predpono velikosti latence. SSD, do katerega dostopa virtualka, je precej hiter in ima latenco v rangu 200 mikrosekund, kjer sta pomembni še minimum in maksimum vrednosti latence. Standardni odklon (mdev) nam pove kakšen razpon latenc lahko pričakujemo pri večini operacij. Na sliki \ref{fig:5_ioping1} so predstavljeni rezultati testa ioPing, kjer lahko vidimo odzivne čase.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{Img/ioping1.png}
    \caption{test ioPing.}
    \label{fig:5_ioping1}
\end{figure}

\subsection{Fio}
Četrti benchmark, ki sva ga pognala je program fio, kar pomeni "flexible I/O". Fio je precej fleksibilen in torej bolj kompleksen program za testiranje diskovja, omogoča več specifičnih testov. Uporabljajo ga razvijalci in administratorji, za testiranje delovanje diskovja in datotečnih sistemov. Midva sva ga uporabila za test pasovne širine pisanja/branja, samo pisanja ali samo branja na disk. V povprečju neka standardna podatkovna baza dobi 3 bralne operacije za vsako pisalno operacijo, torej je razmerje med read in write operacijami 3:1. To razmerje sva uporabila pri testu kombinacije pisanja in branja. Na sliki \ref{fig:6_fio1} so predstavljeni rezultati testa Fio za read in write.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.4]{Img/fio1.png}
    \caption{test Fio, R/W.}
    \label{fig:6_fio1}
\end{figure}

\subsection{Lastnosti metrik testov}

\begin{table}[H]
    \centering
        \begin{tabular}{ | r | r | r | r | r |} 
            \hline
            Metrike & Geekbench 3 & iPerf & ioPing & Fio  \\
            \hline
            linearnost & NE & DA & NE & NE \\
            zanesljivost & NE & DA & NE & DA  \\
            ponovljivost & DA & NE & DA & NE  \\
            enostavnost & NE & DA & DA & DA  \\
            konsistentnost & DA & DA & NE & DA  \\
            neodvisnost & NE & DA & DA & DA  \\
            \hline
        \end{tabular}
        \caption{Tabela prikazuje metrike uporabljenih testov.}
    \label{table:1_chunks}
\end{table}



\section{Zmogljivost omrežnih povezav}

Merjenje zmogljivosti povezav do virtualnega računalnika sva izmerila z uporabo orodja PING in Traceroute.

\subsection{RTT}
Pri naslednjih razdelki se bo uporabljala beseda RTT, katero bom definiral tukaj. RTT (angl. Round Trip Time) ali po slovensko čas povratnega potovanja. Z besedo opišemo čas, ki je potreben za pošiljanje in prihod paketa do destinacije + čas potovanja potrditve do izvora.

\subsection{Ping}
Ping je administracijsko programsko orodje, katerega se uporablja za testiranje dosegljivosti in latence nekega omrežja preko IP protokola. Ping meri RTT sporočil poslanih od izvora do destinacije. Deluje na protokolu ICMP, kateri pošlje zahtevo in počaka na odziv.

\subsection{TraceRoute}
TraceRoute je orodje, ki se uporablja za prikaz poti od izvora do destinacije preko protokola IP. Zgodovina skokov paketa je shranjena kot RTT paketov prejetih od vsakega naslednjega vozlišča. Vsota povprečnih časov vsakega skoka je meritev celotnega časa potrebnega za vzpostavitev povezave.

\subsection{Implementacija}
Na virtualnem računalniku je bilo potrebno nastaviti pravilo, da se računalnik odziva na ICMP pakete katere prejme. Neodzivanje na ICMP pakete se lepo vidi iz slike \ref{fig:6_traceroute1}, kjer * predstavljajo vse usmerjevalnike na poti kateri se niso odzvali, saj Microsoft zavrača vse prihode pakete na njihove strežnike z namenom večje varnosti. Na sliki \ref{fig:6_traceroute1} se vidi testiranje iz lokacije Kranja, medtem ko na sliki \ref{fig:6_traceroute2} lahko vidimo testiranje iz lokacije Brezovica pri Ljubljani. Virtualni računalnik se nahaja na Nizozemskem zato je zadnjih nekaj skokov skoraj enakih, razlikujejo se le v številkah serverja, skozi katerega so paketi potovali.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.45]{Img/traceroute1.png}
    \caption{prikaz poti iz Kranja do virtualnega računalnika.}
    \label{fig:6_traceroute1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{Img/traceroute2.png}
    \caption{prikaz poti iz Brezovice pri Ljubljani do virtualnega računalnika.}
    \label{fig:6_traceroute2}
\end{figure}

Nato sva vsak iz svojega računalnika pognala program ping in testirala RTT do virtualke iz obeh lokacij. Ker sva doma v različnih krajih in imava različne ponudnike interneta, se časi seveda razlikujejo.
\begin{table}[H]
	\centering
	\begin{tabular}{ | r | r | r | r |} 
		\hline
		Lokacija & Min [ms] 3 & Povprečje [ms] & Max [ms]  \\
		\hline
		Kranj & 29.3 & 29.6 & 30.5  \\
		Brezovica pri Ljubljani & 23.3 & 24.1 & 25.7  \\
		\hline
	\end{tabular}
	\caption{Tabela prikazuje metrike uporabljenih testov.}
	\label{table:1_chunks}
\end{table}

Izmerila sva tudi spreminjanje latence čez dan, kjer sva merila ne le povprečne čase, ampak tudi minimalno in maksimalno vrednost. Ponoči je opazno večja maksimalna latenca, ni pa nama jasno zakaj je ravno ponoči taka razlika.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{Img/latenca_cez_dan.png}
	\caption{spreminjanje vrednosti latence čez dan.}
	\label{fig:6_traceroute2}
\end{figure}

%||||||||||||||||||||||||||||| EXAMPLI ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||

%Koda je predstavljena v izpisu \ref{lst:1_lst_cpu}.
%\begin{lstlisting}[caption={Primer testiranja procesorja.}, label={lst:1_lst_cpu}]
%zzrs@ZZRS:~$ sysbench --test=cpu --cpu-max-prime=20000 run
%sysbench 0.4.12:  multi-threaded system evaluation benchmark

%Running the test with following options:
%Number of threads: 1

%Doing CPU performance benchmark

%Threads started!
%Done.

%Maximum prime number checked in CPU test: 20000


%Test execution summary:
   % total time:                          29.6635s
    %total number of events:              10000
    %total time taken by event execution: 29.6616
    %per-request statistics:
       %  min:                                  2.55ms
         %avg:                                  2.97ms
        % max:                                 56.83ms
       %  approx.  95 percentile:               3.33ms

%Threads fairness:
   % events (avg/stddev):           10000.0000/0.00
    %execution time (avg/stddev):   29.6616/0.00
%\end{lstlisting}



\section{Zaključek}
Tule bo zaključek.

